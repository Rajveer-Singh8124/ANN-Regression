{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7377</th>\n",
       "      <td>7378</td>\n",
       "      <td>15592999</td>\n",
       "      <td>Reid</td>\n",
       "      <td>691</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>115465.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60622.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9490</th>\n",
       "      <td>9491</td>\n",
       "      <td>15655171</td>\n",
       "      <td>Yermakova</td>\n",
       "      <td>624</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65801.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>6393</td>\n",
       "      <td>15701352</td>\n",
       "      <td>Fanucci</td>\n",
       "      <td>611</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>96381.68</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>181419.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7777</th>\n",
       "      <td>7778</td>\n",
       "      <td>15638730</td>\n",
       "      <td>Macleod</td>\n",
       "      <td>711</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>82844.33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1408.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7902</th>\n",
       "      <td>7903</td>\n",
       "      <td>15613962</td>\n",
       "      <td>Kenechi</td>\n",
       "      <td>499</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183042.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  ...  IsActiveMember EstimatedSalary Exited\n",
       "7377       7378    15592999       Reid  ...               1        60622.61      0\n",
       "9490       9491    15655171  Yermakova  ...               1        65801.44      0\n",
       "6392       6393    15701352    Fanucci  ...               0       181419.29      0\n",
       "7777       7778    15638730    Macleod  ...               1         1408.68      0\n",
       "7902       7903    15613962    Kenechi  ...               1       183042.20      0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/Churn_Modelling.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"RowNumber\",\"CustomerId\",\"Surname\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding Gender\n",
    "label_encoding_gender = LabelEncoder()\n",
    "df[\"Gender\"] = label_encoding_gender.fit_transform(df[\"Gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encoding Geography\n",
    "ohe_geo = OneHotEncoder()\n",
    "ohe_geo_encoding = ohe_geo.fit(df[[\"Geography\"]])\n",
    "ohe_geo_encoding_transform = ohe_geo_encoding.transform(df[[\"Geography\"]]).toarray()\n",
    "ohe_geo_encoding_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df =  pd.DataFrame(ohe_geo_encoding_transform,columns=ohe_geo_encoding.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([geo_df,df.drop(\"Geography\",axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_df.drop(\"EstimatedSalary\",axis=1)\n",
    "y = new_df[\"EstimatedSalary\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 64)                832       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2945 (11.50 KB)\n",
      "Trainable params: 2945 (11.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64,activation=\"relu\",input_shape=(x_train.shape[1],)),\n",
    "    Dense(32,activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"mean_absolute_error\",metrics=[\"mae\"])\n",
    "\n",
    "early_Stopping_callback = EarlyStopping(monitor=\"val_loss\",patience=10,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "log_dir = \"regressionlog/fit\"+datetime.datetime.now().strftime(\"%Y%M%D-%H%M%S\")\n",
    "tf_callback =TensorBoard(log_dir=log_dir,histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From e:\\ANN\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From e:\\ANN\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "250/250 [==============================] - 12s 17ms/step - loss: 100370.3203 - mae: 100370.3203 - val_loss: 98489.0391 - val_mae: 98489.0391\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 99507.3594 - mae: 99507.3594 - val_loss: 96725.7734 - val_mae: 96725.7734\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 96411.0703 - mae: 96411.0703 - val_loss: 92178.3281 - val_mae: 92178.3281\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 90347.0391 - mae: 90347.0391 - val_loss: 84722.3438 - val_mae: 84722.3438\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 81714.1094 - mae: 81714.1094 - val_loss: 75498.9766 - val_mae: 75498.9766\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 72060.4844 - mae: 72060.4844 - val_loss: 66344.0703 - val_mae: 66344.0703\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 63228.9297 - mae: 63228.9297 - val_loss: 58831.5430 - val_mae: 58831.5430\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 56703.0195 - mae: 56703.0195 - val_loss: 53967.6406 - val_mae: 53967.6406\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 52874.9844 - mae: 52874.9844 - val_loss: 51644.8086 - val_mae: 51644.8086\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 51138.5195 - mae: 51138.5195 - val_loss: 50835.0859 - val_mae: 50835.0859\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 50502.0938 - mae: 50502.0938 - val_loss: 50598.9688 - val_mae: 50598.9688\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 50266.8711 - mae: 50266.8711 - val_loss: 50526.8789 - val_mae: 50526.8789\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 50164.9375 - mae: 50164.9375 - val_loss: 50475.3828 - val_mae: 50475.3828\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 50098.6406 - mae: 50098.6406 - val_loss: 50446.1992 - val_mae: 50446.1992\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 50046.2188 - mae: 50046.2188 - val_loss: 50413.9531 - val_mae: 50413.9531\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 50002.5078 - mae: 50002.5078 - val_loss: 50388.4336 - val_mae: 50388.4336\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 49967.5391 - mae: 49967.5391 - val_loss: 50376.9766 - val_mae: 50376.9766\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 49933.1328 - mae: 49933.1328 - val_loss: 50362.1484 - val_mae: 50362.1484\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 49906.8789 - mae: 49906.8789 - val_loss: 50346.0977 - val_mae: 50346.0977\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 49874.3125 - mae: 49874.3125 - val_loss: 50332.6406 - val_mae: 50332.6406\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 49847.3711 - mae: 49847.3711 - val_loss: 50317.8711 - val_mae: 50317.8711\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 49824.5312 - mae: 49824.5312 - val_loss: 50319.0469 - val_mae: 50319.0469\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 49801.4336 - mae: 49801.4336 - val_loss: 50304.7422 - val_mae: 50304.7422\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 49781.3281 - mae: 49781.3281 - val_loss: 50291.5625 - val_mae: 50291.5625\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 49760.4648 - mae: 49760.4648 - val_loss: 50288.1758 - val_mae: 50288.1758\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 49743.3633 - mae: 49743.3633 - val_loss: 50290.4805 - val_mae: 50290.4805\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 49725.0508 - mae: 49725.0508 - val_loss: 50273.9102 - val_mae: 50273.9102\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 49711.8594 - mae: 49711.8594 - val_loss: 50266.0156 - val_mae: 50266.0156\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 49696.1211 - mae: 49696.1211 - val_loss: 50257.8555 - val_mae: 50257.8555\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 49680.8438 - mae: 49680.8438 - val_loss: 50258.8711 - val_mae: 50258.8711\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 49667.5898 - mae: 49667.5898 - val_loss: 50245.0664 - val_mae: 50245.0664\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 49654.9102 - mae: 49654.9102 - val_loss: 50246.2383 - val_mae: 50246.2383\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 49640.6992 - mae: 49640.6992 - val_loss: 50225.4336 - val_mae: 50225.4336\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 49633.1992 - mae: 49633.1992 - val_loss: 50236.6602 - val_mae: 50236.6602\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 49620.1523 - mae: 49620.1523 - val_loss: 50231.9688 - val_mae: 50231.9688\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 49611.3086 - mae: 49611.3086 - val_loss: 50229.4375 - val_mae: 50229.4375\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 49598.3516 - mae: 49598.3516 - val_loss: 50226.1328 - val_mae: 50226.1328\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 49587.8867 - mae: 49587.8867 - val_loss: 50220.6250 - val_mae: 50220.6250\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 49578.6719 - mae: 49578.6719 - val_loss: 50218.5625 - val_mae: 50218.5625\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 49572.2656 - mae: 49572.2656 - val_loss: 50211.8203 - val_mae: 50211.8203\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 49564.4883 - mae: 49564.4883 - val_loss: 50220.3281 - val_mae: 50220.3281\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 49551.2578 - mae: 49551.2578 - val_loss: 50214.1680 - val_mae: 50214.1680\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 49545.0039 - mae: 49545.0039 - val_loss: 50217.4141 - val_mae: 50217.4141\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 49539.3828 - mae: 49539.3828 - val_loss: 50223.4219 - val_mae: 50223.4219\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 49531.7578 - mae: 49531.7578 - val_loss: 50214.2148 - val_mae: 50214.2148\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 49521.1719 - mae: 49521.1719 - val_loss: 50220.0859 - val_mae: 50220.0859\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 49511.4766 - mae: 49511.4766 - val_loss: 50218.1719 - val_mae: 50218.1719\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 49502.6406 - mae: 49502.6406 - val_loss: 50221.6367 - val_mae: 50221.6367\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 49500.5703 - mae: 49500.5703 - val_loss: 50222.6211 - val_mae: 50222.6211\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 49490.2422 - mae: 49490.2422 - val_loss: 50229.4570 - val_mae: 50229.4570\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train_scaled,y_train,validation_data =(x_test_scaled,y_test),\n",
    "    epochs=100, callbacks=[early_Stopping_callback,tf_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-deb40bb10e969939\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-deb40bb10e969939\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir regressionlog/fit20240212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 5ms/step - loss: 50211.8203 - mae: 50211.8203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50211.8203125"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss,test_mae = model.evaluate(x_test_scaled,y_test)\n",
    "test_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANN\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"data/regression_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
